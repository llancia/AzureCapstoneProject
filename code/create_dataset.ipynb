{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from azureml.core import Dataset, Datastore\r\n",
        "from azureml.core import Workspace\r\n",
        "import os\r\n",
        "\r\n",
        "\r\n",
        "ws = Workspace.from_config()\r\n",
        "datastore =  ws.get_default_datastore()\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 1,
      "metadata": {
        "gather": {
          "logged": 1631089027577
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "dataset_name = \"HrAnalytics-DataScientist\"\r\n",
        "description = \"\"\"\"\"\"\r\n",
        "local_path = r\"../data/\"\r\n",
        "dataset_file = 'aug_train.csv'\r\n",
        "datastore_path = 'udacity-lancia'\r\n",
        "datastore.upload(src_dir=local_path, target_path=datastore_path)\r\n",
        "\r\n",
        "\r\n",
        "dataset_file_remote = os.path.join(datastore_path,dataset_file)\r\n",
        "ds = Dataset.Tabular.from_delimited_files(path=[(datastore, (dataset_file_remote))])\r\n",
        "\r\n",
        "\r\n",
        "try:\r\n",
        "    ds = ds.register(ws,\r\n",
        "                name= dataset_name,\r\n",
        "                description=description)\r\n",
        "except Exception:\r\n",
        "    print(\"creating new version of dataset\")\r\n",
        "    ds = ds.register(ws,\r\n",
        "                name= dataset_name,\r\n",
        "                description=description,\r\n",
        "                create_new_version=True)\r\n",
        "\r\n",
        "\r\n",
        "df = ds.to_pandas_dataframe()\r\n",
        "df.head()"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Uploading an estimated of 3 files\nTarget already exists. Skipping upload for udacity-lancia/.amlignore\nTarget already exists. Skipping upload for udacity-lancia/.amlignore.amltmp\nTarget already exists. Skipping upload for udacity-lancia/.gitignore\nUploaded 0 files\n"
        },
        {
          "output_type": "execute_result",
          "execution_count": 5,
          "data": {
            "text/plain": "   enrollee_id      city  city_development_index gender  \\\n0         8949  city_103                   0.920   Male   \n1        29725   city_40                   0.776   Male   \n2        11561   city_21                   0.624   None   \n3        33241  city_115                   0.789   None   \n4          666  city_162                   0.767   Male   \n\n       relevent_experience enrolled_university education_level  \\\n0  Has relevent experience       no_enrollment        Graduate   \n1   No relevent experience       no_enrollment        Graduate   \n2   No relevent experience    Full time course        Graduate   \n3   No relevent experience                None        Graduate   \n4  Has relevent experience       no_enrollment         Masters   \n\n  major_discipline experience company_size    company_type last_new_job  \\\n0             STEM        >20         None            None            1   \n1             STEM         15        50-99         Pvt Ltd           >4   \n2             STEM          5         None            None        never   \n3  Business Degree         <1         None         Pvt Ltd        never   \n4             STEM        >20        50-99  Funded Startup            4   \n\n   training_hours  target  \n0              36     1.0  \n1              47     0.0  \n2              83     0.0  \n3              52     1.0  \n4               8     0.0  ",
            "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>enrollee_id</th>\n      <th>city</th>\n      <th>city_development_index</th>\n      <th>gender</th>\n      <th>relevent_experience</th>\n      <th>enrolled_university</th>\n      <th>education_level</th>\n      <th>major_discipline</th>\n      <th>experience</th>\n      <th>company_size</th>\n      <th>company_type</th>\n      <th>last_new_job</th>\n      <th>training_hours</th>\n      <th>target</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>8949</td>\n      <td>city_103</td>\n      <td>0.920</td>\n      <td>Male</td>\n      <td>Has relevent experience</td>\n      <td>no_enrollment</td>\n      <td>Graduate</td>\n      <td>STEM</td>\n      <td>&gt;20</td>\n      <td>None</td>\n      <td>None</td>\n      <td>1</td>\n      <td>36</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>29725</td>\n      <td>city_40</td>\n      <td>0.776</td>\n      <td>Male</td>\n      <td>No relevent experience</td>\n      <td>no_enrollment</td>\n      <td>Graduate</td>\n      <td>STEM</td>\n      <td>15</td>\n      <td>50-99</td>\n      <td>Pvt Ltd</td>\n      <td>&gt;4</td>\n      <td>47</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>11561</td>\n      <td>city_21</td>\n      <td>0.624</td>\n      <td>None</td>\n      <td>No relevent experience</td>\n      <td>Full time course</td>\n      <td>Graduate</td>\n      <td>STEM</td>\n      <td>5</td>\n      <td>None</td>\n      <td>None</td>\n      <td>never</td>\n      <td>83</td>\n      <td>0.0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>33241</td>\n      <td>city_115</td>\n      <td>0.789</td>\n      <td>None</td>\n      <td>No relevent experience</td>\n      <td>None</td>\n      <td>Graduate</td>\n      <td>Business Degree</td>\n      <td>&lt;1</td>\n      <td>None</td>\n      <td>Pvt Ltd</td>\n      <td>never</td>\n      <td>52</td>\n      <td>1.0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>666</td>\n      <td>city_162</td>\n      <td>0.767</td>\n      <td>Male</td>\n      <td>Has relevent experience</td>\n      <td>no_enrollment</td>\n      <td>Masters</td>\n      <td>STEM</td>\n      <td>&gt;20</td>\n      <td>50-99</td>\n      <td>Funded Startup</td>\n      <td>4</td>\n      <td>8</td>\n      <td>0.0</td>\n    </tr>\n  </tbody>\n</table>\n</div>"
          },
          "metadata": {}
        }
      ],
      "execution_count": 5,
      "metadata": {
        "gather": {
          "logged": 1631092131132
        }
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Pipeline for preprocessing"
      ],
      "metadata": {
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.runconfig import RunConfiguration\r\n",
        "from azureml.core import Environment\r\n",
        "from azureml.core.conda_dependencies import CondaDependencies\r\n",
        "env = Environment('dataprep')\r\n",
        "\r\n",
        "conda = CondaDependencies()\r\n",
        "conda.add_conda_package(\"python=3.8\")\r\n",
        "\r\n",
        "# add pip packages\r\n",
        "conda.add_pip_package('azureml-core')\r\n",
        "conda.add_pip_package('pandas')\r\n",
        "conda.add_pip_package('numpy')\r\n",
        "conda.add_pip_package(\"scikit-learn==0.22.2.post1\")\r\n",
        "\r\n",
        "# add conda dependencies to environment\r\n",
        "env.python.conda_dependencies = conda\r\n"
      ],
      "outputs": [],
      "execution_count": 8,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631092292370
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.compute import ComputeTarget\r\n",
        "def_compute_target = ComputeTarget(ws,name=\"lancia\")\r\n",
        "\r\n",
        "\r\n",
        "runconfig = RunConfiguration()\r\n",
        "runconfig.environment  = env\r\n",
        "runconfig.target = def_compute_target\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 9,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631093420067
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData\r\n",
        "from azureml.pipeline.steps import PythonScriptStep\r\n",
        "\r\n",
        "\r\n",
        "prepped_data = PipelineData(name=\"prepared_data\").as_dataset()\r\n",
        "\r\n",
        "dataprep_step = PythonScriptStep(\r\n",
        "    name=\"dataprep\", \r\n",
        "    script_name=\"dataprep.py\",\r\n",
        "    source_directory=\"./steps_scripts/prep\",\r\n",
        "    arguments=[\"--output_path\", prepped_data],\r\n",
        "    inputs=[ds.as_named_input('input_ds')],\r\n",
        "    outputs=[prepped_data],\r\n",
        "    runconfig=runconfig,\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n"
      ],
      "outputs": [],
      "execution_count": 10,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631093420938
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData\r\n",
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "\r\n",
        "train_data = PipelineData(name=\"train_data\").as_dataset()\r\n",
        "test_data =  PipelineData(name=\"test_data\").as_dataset()\r\n",
        "\r\n",
        "split_step = PythonScriptStep(\r\n",
        "    name=\"train_test_split\", \r\n",
        "    script_name=\"train_test_split.py\", \r\n",
        "    source_directory=\"./steps_scripts/split/\",\r\n",
        "    arguments=[\"--train_path\", train_data, \"--test_path\", test_data],\r\n",
        "    inputs=[prepped_data.parse_delimited_files().as_named_input(\"prepped_data\")],\r\n",
        "    outputs=[train_data, test_data],\r\n",
        "    runconfig=runconfig,\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 11,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631093422665
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import PipelineData\r\n",
        "from azureml.data import OutputFileDatasetConfig\r\n",
        "\r\n",
        "dataset_prefix  = \"HRAnalytics\"\r\n",
        "register_dastaset_step = PythonScriptStep(\r\n",
        "    name=\"Register_Datasets\", \r\n",
        "    script_name=\"register_dataset.py\", \r\n",
        "    source_directory=\"./steps_scripts/dataset/\",\r\n",
        "    arguments=[\"--dataset_prefix\", dataset_prefix, \"--register_datasets\", \"train_dataset\", \"test_dastest\"], \r\n",
        "    inputs=[train_data.parse_delimited_files().as_named_input(\"train_dataset\"), test_data.parse_delimited_files().as_named_input(\"test_dastest\")],\r\n",
        "    runconfig=runconfig,\r\n",
        "    allow_reuse=True\r\n",
        ")\r\n",
        "\r\n",
        "\r\n",
        "\r\n"
      ],
      "outputs": [],
      "execution_count": 29,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631095904958
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.pipeline.core import Pipeline\r\n",
        "pipeline = Pipeline(\r\n",
        "    description=\"AzureMlE-preprocessing\",\r\n",
        "    workspace=ws,    \r\n",
        "    steps=[dataprep_step,\r\n",
        "    split_step,\r\n",
        "    register_dastaset_step])"
      ],
      "outputs": [],
      "execution_count": 30,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631095906803
        }
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from azureml.core.experiment import Experiment\r\n",
        "\r\n",
        "experiment= Experiment(ws, \"AzureMlE-Preprocessing-Pipe\")\r\n",
        "\r\n",
        "remote_run = experiment.submit(pipeline)"
      ],
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": "Created step dataprep [2ad6f71f][b152e88b-97f3-423d-88d0-6cab2c73928d], (This step is eligible to reuse a previous run's output)\nCreated step train_test_split [6e231a9d][8912289d-6bb6-43f1-9f1e-eb76442432c1], (This step is eligible to reuse a previous run's output)\nCreated step Register_Datasets [5f6d11e1][9cf1c8b9-c65b-4e9e-8ebc-dbc128447767], (This step will run and generate new outputs)\nSubmitted PipelineRun 1acc1a5f-c231-497e-b8d8-8b0e29262934\nLink to Azure Machine Learning Portal: https://ml.azure.com/runs/1acc1a5f-c231-497e-b8d8-8b0e29262934?wsid=/subscriptions/ec5ba19e-6205-418f-a52d-d0943090ca16/resourcegroups/rg-wwe-ictx-dsplayground/workspaces/aml-wwe-ictx-dsplay&tid=c16e514b-893e-4a01-9a30-b8fef514a650\n"
        }
      ],
      "execution_count": 31,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        },
        "gather": {
          "logged": 1631095910396
        }
      }
    },
    {
      "cell_type": "code",
      "source": [],
      "outputs": [],
      "execution_count": null,
      "metadata": {
        "jupyter": {
          "source_hidden": false,
          "outputs_hidden": false
        },
        "nteract": {
          "transient": {
            "deleting": false
          }
        }
      }
    }
  ],
  "metadata": {
    "orig_nbformat": 4,
    "language_info": {
      "name": "python",
      "version": "3.6.9",
      "mimetype": "text/x-python",
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "pygments_lexer": "ipython3",
      "nbconvert_exporter": "python",
      "file_extension": ".py"
    },
    "kernelspec": {
      "name": "python3",
      "language": "python",
      "display_name": "Python 3"
    },
    "interpreter": {
      "hash": "c2d7162e38cbe972ab9d255938448a87119f02533632fac9812f642a39a25e97"
    },
    "kernel_info": {
      "name": "python3"
    },
    "nteract": {
      "version": "nteract-front-end@1.0.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}